<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SpringBoot+Lucene案例介绍]]></title>
    <url>%2F2019%2F06%2F07%2FSpringBoot%2BLucene%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[SpringBoot+Lucene案例介绍GitHub仓库:https://github.com/yizuoliang/blog/tree/master/Full-text%20Retrieval/02_SpringBoot%2BLucene 一、案例介绍 模拟一个商品的站内搜索系统（类似淘宝的站内搜索）； 商品详情保存在mysql数据库的product表中，使用mybatis框架； 站内查询使用Lucene创建索引，进行全文检索； 增、删、改，商品需要对Lucene索引修改，搜索也要达到近实时的效果。 对于数据库的操作和配置就不在本文中体现，主要讲解与Lucene的整合。 一、引入lucene的依赖向pom文件中引入依赖 123456789101112131415161718192021222324252627282930&lt;!--核心包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--对分词索引查询解析--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--一般分词器，适用于英文分词--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--检索关键字高亮显示 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- smartcn中文分词器 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-smartcn&lt;/artifactId&gt; &lt;version&gt;7.6.0&lt;/version&gt;&lt;/dependency&gt; 三、配置初始化Bean类初始化bean类需要知道的几点： 1.实例化 IndexWriter，IndexSearcher 都需要去加载索引文件夹，实例化是是非常消耗资源的，所以我们希望只实例化一次交给spring管理。 2.IndexSearcher 我们一般通过SearcherManager管理，因为IndexSearcher 如果初始化的时候加载了索引文件夹，那么 后面添加、删除、修改的索引都不能通过IndexSearcher 查出来，因为它没有与索引库实时同步，只是第一次有加载。 3.ControlledRealTimeReopenThread创建一个守护线程，如果没有主线程这个也会消失，这个线程作用就是定期更新让SearchManager管理的search能获得最新的索引库，下面是每25S执行一次。 4.要注意引入的lucene版本，不同的版本用法也不同，许多api都有改变。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Configurationpublic class LuceneConfig &#123; /** * lucene索引,存放位置 */ private static final String LUCENEINDEXPATH=&quot;lucene/indexDir/&quot;; /** * 创建一个 Analyzer 实例 * * @return */ @Bean public Analyzer analyzer() &#123; return new SmartChineseAnalyzer(); &#125; /** * 索引位置 * * @return * @throws IOException */ @Bean public Directory directory() throws IOException &#123; Path path = Paths.get(LUCENEINDEXPATH); File file = path.toFile(); if(!file.exists()) &#123; //如果文件夹不存在,则创建 file.mkdirs(); &#125; return FSDirectory.open(path); &#125; /** * 创建indexWriter * * @param directory * @param analyzer * @return * @throws IOException */ @Bean public IndexWriter indexWriter(Directory directory, Analyzer analyzer) throws IOException &#123; IndexWriterConfig indexWriterConfig = new IndexWriterConfig(analyzer); IndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig); // 清空索引 indexWriter.deleteAll(); indexWriter.commit(); return indexWriter; &#125; /** * SearcherManager管理 * * @param directory * @return * @throws IOException */ @Bean public SearcherManager searcherManager(Directory directory, IndexWriter indexWriter) throws IOException &#123; SearcherManager searcherManager = new SearcherManager(indexWriter, false, false, new SearcherFactory()); ControlledRealTimeReopenThread cRTReopenThead = new ControlledRealTimeReopenThread(indexWriter, searcherManager, 5.0, 0.025); cRTReopenThead.setDaemon(true); //线程名称 cRTReopenThead.setName(&quot;更新IndexReader线程&quot;); // 开启线程 cRTReopenThead.start(); return searcherManager; &#125;&#125; 四、创建需要的Bean类创建商品Bean 12345678910111213141516171819202122232425262728293031/** * 商品bean类 * @author yizl * */public class Product &#123; /** * 商品id */ private int id; /** * 商品名称 */ private String name; /** * 商品类型 */ private String category; /** * 商品价格 */ private float price; /** * 商品产地 */ private String place; /** * 商品条形码 */ private String code; ...... 创建一个带参数查询分页通用类PageQuery类 123456789101112131415161718192021222324252627/** * 带参数查询分页类 * @author yizl * * @param &lt;T&gt; */public class PageQuery&lt;T&gt; &#123; private PageInfo pageInfo; /** * 排序字段 */ private Sort sort; /** * 查询参数类 */ private T params; /** * 返回结果集 */ private List&lt;T&gt; results; /** * 不在T类中的参数 */ private Map&lt;String, String&gt; queryParam; ...... 五、创建索引库1.项目启动后执行同步数据库方法项目启动后，更新索引库中所有的索引。 1234567891011121314151617181920/** * 项目启动后,立即执行 * @author yizl * */@Component@Order(value = 1)public class ProductRunner implements ApplicationRunner &#123; @Autowired private ILuceneService service; @Override public void run(ApplicationArguments arg0) throws Exception &#123; /** * 启动后将同步Product表,并创建index */ service.synProductCreatIndex(); &#125;&#125; 2.从数据库中查询出所有的商品从数据库中查找出所有的商品 1234567@Overridepublic void synProductCreatIndex() throws IOException &#123; // 获取所有的productList List&lt;Product&gt; allProduct = mapper.getAllProduct(); // 再插入productList luceneDao.createProductIndex(allProduct);&#125; 3.创建这些商品的索引把List中的商品创建索引 我们知道，mysql对每个字段都定义了字段类型，然后根据类型保存相应的值。 那么lucene的存储对象是以document为存储单元，对象中相关的属性值则存放到Field（域）中； Field类的常用类型 Field类 数据类型 是否分词 index是否索引 Stored是否存储 说明 StringField 字符串 N Y Y/N 构建一个字符串的Field,但不会进行分词,将整串字符串存入索引中,适合存储固定(id,身份证号,订单号等) FloatPointLongPointDoublePoint 数值型 Y Y N 这个Field用来构建一个float数字型Field，进行分词和索引，比如(价格) StoredField 重载方法,，支持多种类型 N N Y 这个Field用来构建不同类型Field,不分析，不索引，但要Field存储在文档中 TextField 字符串或者流 Y Y Y/N 一般此对字段需要进行检索查询 上面是一些常用的数据类型, 6.0后的版本，数值型建立索引的字段都更改为Point结尾，FloatPoint，LongPoint，DoublePoint等，对于浮点型的docvalue是对应的DocValuesField，整型为NumericDocValuesField，FloatDocValuesField等都为NumericDocValuesField的实现类。 commit()的用法commit()方法,indexWriter.addDocuments(docs);只是将文档放在内存中,并没有放入索引库,没有commit()的文档,我从索引库中是查询不出来的; 许多博客代码中,都没有进行commit(),但仍然能查出来,因为每次插入,他都把IndexWriter关闭.close(),Lucene关闭前,都会把在内存的文档,提交到索引库中,索引能查出来,在spring中IndexWriter是单例的,不关闭,所以每次对索引都更改时,都需要进行commit()操作; 这样设计的目的,和数据库的事务类似,可以进行回滚,调用rollback()方法进行回滚。 1234567891011121314151617181920212223242526@Autowiredprivate IndexWriter indexWriter;@Overridepublic void createProductIndex(List&lt;Product&gt; productList) throws IOException &#123; List&lt;Document&gt; docs = new ArrayList&lt;Document&gt;(); for (Product p : productList) &#123; Document doc = new Document(); doc.add(new StringField(&quot;id&quot;, p.getId()+&quot;&quot;, Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new StringField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); // 保存price, float price = p.getPrice(); // 建立倒排索引 doc.add(new FloatPoint(&quot;price&quot;, price)); // 正排索引用于排序、聚合 doc.add(new FloatDocValuesField(&quot;price&quot;, price)); // 存储到索引库 doc.add(new StoredField(&quot;price&quot;, price)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new StringField(&quot;code&quot;, p.getCode(), Field.Store.YES)); docs.add(doc); &#125; indexWriter.addDocuments(docs); indexWriter.commit();&#125; 六、多条件查询按条件查询,分页查询都在下面代码中体现出来了,有什么不明白的可以单独查询资料,下面的匹配查询已经比较复杂了. searcherManager.maybeRefresh()方法,刷新searcherManager中的searcher,获取到最新的IndexSearcher。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Autowiredprivate Analyzer analyzer;@Autowiredprivate SearcherManager searcherManager;@Overridepublic PageQuery&lt;Product&gt; searchProduct(PageQuery&lt;Product&gt; pageQuery) throws IOException, ParseException &#123; searcherManager.maybeRefresh(); IndexSearcher indexSearcher = searcherManager.acquire(); Product params = pageQuery.getParams(); Map&lt;String, String&gt; queryParam = pageQuery.getQueryParam(); Builder builder = new BooleanQuery.Builder(); Sort sort = new Sort(); // 排序规则 com.infinova.yimall.entity.Sort sort1 = pageQuery.getSort(); if (sort1 != null &amp;&amp; sort1.getOrder() != null) &#123; if (&quot;ASC&quot;.equals((sort1.getOrder()).toUpperCase())) &#123; sort.setSort(new SortField(sort1.getField(), SortField.Type.FLOAT, false)); &#125; else if (&quot;DESC&quot;.equals((sort1.getOrder()).toUpperCase())) &#123; sort.setSort(new SortField(sort1.getField(), SortField.Type.FLOAT, true)); &#125; &#125; // 模糊匹配,匹配词 String keyStr = queryParam.get(&quot;searchKeyStr&quot;); if (keyStr != null) &#123; // 输入空格,不进行模糊查询 if (!&quot;&quot;.equals(keyStr.replaceAll(&quot; &quot;, &quot;&quot;))) &#123; builder.add(new QueryParser(&quot;name&quot;, analyzer).parse(keyStr), Occur.MUST); &#125; &#125; // 精确查询 if (params.getCategory() != null) &#123; builder.add(new TermQuery(new Term(&quot;category&quot;, params.getCategory())), Occur.MUST); &#125; if (queryParam.get(&quot;lowerPrice&quot;) != null &amp;&amp; queryParam.get(&quot;upperPrice&quot;) != null) &#123; // 价格范围查询 builder.add(FloatPoint.newRangeQuery(&quot;price&quot;, Float.parseFloat(queryParam.get(&quot;lowerPrice&quot;)), Float.parseFloat(queryParam.get(&quot;upperPrice&quot;))), Occur.MUST); &#125; PageInfo pageInfo = pageQuery.getPageInfo(); TopDocs topDocs = indexSearcher.search(builder.build(), pageInfo.getPageNum() * pageInfo.getPageSize(), sort); pageInfo.setTotal(topDocs.totalHits); ScoreDoc[] hits = topDocs.scoreDocs; List&lt;Product&gt; pList = new ArrayList&lt;Product&gt;(); for (int i = 0; i &lt; hits.length; i++) &#123; Document doc = indexSearcher.doc(hits[i].doc); System.out.println(doc.toString()); Product product = new Product(); product.setId(Integer.parseInt(doc.get(&quot;id&quot;))); product.setName(doc.get(&quot;name&quot;)); product.setCategory(doc.get(&quot;category&quot;)); product.setPlace(doc.get(&quot;place&quot;)); product.setPrice(Float.parseFloat(doc.get(&quot;price&quot;))); product.setCode(doc.get(&quot;code&quot;)); pList.add(product); &#125; pageQuery.setResults(pList); return pageQuery;&#125; 七、删除更新索引12345@Overridepublic void deleteProductIndexById(String id) throws IOException &#123; indexWriter.deleteDocuments(new Term(&quot;id&quot;,id)); indexWriter.commit();&#125; 八、补全Spring中剩余代码Controller层 1234567891011121314151617181920@RestController@RequestMapping(&quot;/product/search&quot;)public class ProductSearchController &#123; @Autowired private ILuceneService service; /** * * @param pageQuery * @return * @throws ParseException * @throws IOException */ @PostMapping(&quot;/searchProduct&quot;) private ResultBean&lt;PageQuery&lt;Product&gt;&gt; searchProduct(@RequestBody PageQuery&lt;Product&gt; pageQuery) throws IOException, ParseException &#123; PageQuery&lt;Product&gt; pageResult= service.searchProduct(pageQuery); return ResultUtil.success(pageResult); &#125; &#125; 12345678910111213141516171819public class ResultUtil&lt;T&gt; &#123; public static &lt;T&gt; ResultBean&lt;T&gt; success(T t)&#123; ResultEnum successEnum = ResultEnum.SUCCESS; return new ResultBean&lt;T&gt;(successEnum.getCode(),successEnum.getMsg(),t); &#125; public static &lt;T&gt; ResultBean&lt;T&gt; success()&#123; return success(null); &#125; public static &lt;T&gt; ResultBean&lt;T&gt; error(ResultEnum Enum)&#123; ResultBean&lt;T&gt; result = new ResultBean&lt;T&gt;(); result.setCode(Enum.getCode()); result.setMsg(Enum.getMsg()); result.setData(null); return result; &#125;&#125; 1234567891011121314151617public class ResultBean&lt;T&gt; implements Serializable &#123; private static final long serialVersionUID = 1L; /** * 返回code */ private int code; /** * 返回message */ private String msg; /** * 返回值 */ private T data; ... 12345678910111213141516171819public enum ResultEnum &#123; UNKNOW_ERROR(-1, &quot;未知错误&quot;), SUCCESS(0, &quot;成功&quot;), PASSWORD_ERROR(10001, &quot;用户名或密码错误&quot;), PARAMETER_ERROR(10002, &quot;参数错误&quot;); /** * 返回code */ private Integer code; /** * 返回message */ private String msg; ResultEnum(Integer code, String msg) &#123; this.code = code; this.msg = msg; &#125;]]></content>
      <categories>
        <category>全文检索技术</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lucene介绍与应用]]></title>
    <url>%2F2019%2F06%2F06%2FLucene%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Lucene介绍与应用GitHub仓库:https://github.com/yizuoliang/blog/tree/master/Full-text%20Retrieval 一、全文检索介绍1.数据结构结构化数据：​ 指具有“固定格式” 或“限定长度”的数据； ​ 例如：数据库中的数据、元数据…… 非结构化数据​ 指不定长度或无固定格式的数据； ​ 例如：文本、图片、视频、图表…… 2.数据的搜索顺序扫描法​ 从第一个文件扫描到最后一个文件，把每一个文件内容从开头扫到结尾，直到扫完所有的文件。 全文检索法​ 将非结构化数据中的一部分信息提取出来，重新组织，建立索引，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。 3.全文检索例如：新华字典。字典的拼音表和部首检字表就相当于字典的索引，我们可以通过查找索引从而找到具体的字解释。如果没有创建索引，就要从字典的首页一页页地去查找。 这种先建立索引，再对索引进行搜索的过程就叫全文检索(Full-text Search) 。 全文检索的核心创建索引：将从所有的结构化和非结构化数据提取信息，创建索引的过程。 搜索索引：就是得到用户的查询请求，搜索创建的索引，然后返回结果的过程。 4.倒排索引 倒排索引（英文：InvertedIndex），也称为反向索引，是一种索引方法，实现“单词-文档矩阵”的一种具体存储形式，常被用于存储在全文搜索下某个单词与文档的存储位置的映射，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。 倒排索引的结构主要由两个部分组成：“单词词典”和“倒排表”。 索引方法例子 ​ 3个文档内容为： ​ 1.php是过去最流行的语言。 ​ 2.java是现在最流行的语言。 ​ 3. Python是未来流行的语言。 倒排索引的创建​ 1.使用分词系统将文档切分成单词序列，每个文档就成了由由单词序列构成的数据流； ​ 2.给不同的单词赋予唯一的单词id,记录下对应的单词; ​ 3.同时记录单词出现的文档,形成倒排列表。每个单词都指向了文档(Document)链表。 倒排索引的查询​ 假如说用户需要查询: “现在流行” ​ 1.将用户输入进行分词,分为”现在”和”流行”; ​ 2.取出包含字符串“现在”的文档链表; ​ 3.取出包含字符串“流行”的文档链表; ​ 4.通过合并链表,找出包含有”现在”或者”流行”的链表。 倒排索引原理当然倒排索引的结构也不是上面说的那么简单，索引系统还可以记录除此之外的更多信息。词对应的倒排列表不仅记录了文档编号还记录了单词频率信息。词频信息在搜索结果时，是重要的排序依据。这里先了解下，后面的评分计算就要用到这个。 索引和搜索流程图 二、Lucene入门• Lucene是一套用于全文检索和搜寻的开源程序库，由Apache软件基金会支持和提供; • 基于java的全文检索工具包, Lucene并不是现成的搜索引擎产品，但可以用来制作搜索引擎产品； • 官网：http://lucene.apache.org/ 。 1.Lucene的总体结构 从lucene的总体架构图可以看出： ​ 1.Lucene库提供了创建索引和搜索索引的API。 ​ 2.应用程序需要做的就是收集文档数据，创建索引；通过用户输入查询索引的得到返回结果。 2.Lucene的几个基本概念Index（索引）：类似数据库的表的概念，但它完全没有约束，可以修改和添加里面的文档，文档里的内容可以任意定义。 Document（文档）：类似数据库内的行的概念，一个Index内会包含多个Document。 Field（字段）：一个Document会由一个或多个Field组成，分词就是对Field 分词。 Term（词语）和Term Dictionary（词典）：Lucene中索引和搜索的最小单位，一个Field会由一个或多个Term组成，Term是由Field经过Analyzer（分词）产生。Term Dictionary即Term词典，是根据条件查找Term的基本索引。 3.Lucene创建索引过程Lucene创建索引过程如下： 1.创建一个IndexWriter用来写索引文件，它有几个参数，INDEX_DIR就是索引文件所存放的位置，Analyzer便是用来 对文档进行词法分析和语言处理的。 2.创建一个Document代表我们要索引的文档。将不同的Field加入到文档中。不同类型的信息用不同的Field来表示 3.IndexWriter调用函数addDocument将索引写到索引文件夹中。 4.Lucene搜索过程搜索过程如下： 1.IndexReader将磁盘上的索引信息读入到内存，INDEX_DIR就是索引文件存放的位置。 2.创建IndexSearcher准备进行搜索。 3.创建Analyer用来对查询语句进行词法分析和语言处理。 4.创建QueryParser用来对查询语句进行语法分析。 5.QueryParser调用parser进行语法分析，形成查询语法树，放到Query中。 6.IndexSearcher调用search对查询语法树Query进行搜索，得到结果TopScoreDocCollector。 三、Lucene入门案例一1.案例一代码引入lucene的jar包 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public class LuceneTest &#123; public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 创建索引 List&lt;String&gt; productNames = new ArrayList&lt;&gt;(); productNames.add(&quot;小天鹅TG100-1420WDXG&quot;); productNames.add(&quot;小天鹅TB80-easy60W 洗漂脱时间自由可调，京东微联智能APP手机控制&quot;); productNames.add(&quot;小天鹅TG90-1411DG 洗涤容量:9kg 脱水容量:9kg 显示屏:LED数码屏显示&quot;); productNames.add(&quot;小天鹅TP75-V602 流线蝶形波轮，超强喷淋漂洗&quot;); productNames.add(&quot;小天鹅TG100V20WDG 大件洗，无旋钮外观，智能WiFi&quot;); productNames.add(&quot;小天鹅TD80-1411DG 洗涤容量:8kg 脱水容量:8kg 显示屏:LED数码屏显示&quot;); productNames.add(&quot;海尔XQB90-BZ828 洗涤容量:9kg 脱水容量:9kg 显示屏:LED数码屏显示&quot;); productNames.add(&quot;海尔G100818HBG 极简智控面板，V6蒸汽烘干，深层洁净&quot;); productNames.add(&quot;海尔G100678HB14SU1 洗涤容量:10kg 脱水容量:10kg 显示屏:LED数码屏显&quot;); productNames.add(&quot;海尔XQB80-KM12688 智能自由洗，超净洗&quot;); productNames.add(&quot;海尔EG8014HB39GU1 手机智能，一键免熨烫，空气净化洗&quot;); productNames.add(&quot;海尔G100818BG 琥珀金机身，深层洁净，轻柔雪纺洗&quot;); productNames.add(&quot;海尔G100728BX12G 安全磁锁，健康下排水&quot;); productNames.add(&quot;西门子XQG80-WD12G4C01W 衣干即停，热风除菌，低噪音&quot;); productNames.add(&quot;西门子XQG80-WD12G4681W 智能烘干，变速节能，无刷电机&quot;); productNames.add(&quot;西门子XQG100-WM14U568LW 洗涤容量:10kg 脱水容量:10kg 显示屏:LED&quot;); productNames.add(&quot;西门子XQG80-WM10N1C80W 除菌、洗涤分离，防过敏程序&quot;); productNames.add(&quot;西门子XQG100-WM14U561HW 洗涤容量:10kg 脱水容量:10kg 显示屏:LED&quot;); productNames.add(&quot;西门子XQG80-WM12L2E88W 洗涤容量:8kg 脱水容量:8kg 显示屏:LED触摸&quot;); Directory index = createIndex(analyzer, productNames); // 3. 查询器 String keyword = &quot;西门子 LED&quot;; Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher = new IndexSearcher(reader); int numberPerPage = 1000; System.out.printf(&quot;当前一共有%d条数据%n&quot;+&quot;&lt;br&gt;&quot;, productNames.size()); System.out.printf(&quot;查询关键字是：\&quot;%s\&quot;%n&quot;+&quot;&lt;br&gt;&quot;, keyword); ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs; // 5. 显示查询结果 showSearchResults(searcher, hits, query, analyzer); // 6. 关闭查询 reader.close(); &#125; private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;找到 &quot; + hits.length + &quot; 个命中. &lt;br&gt;&quot;); System.out.println(&quot;序号\t匹配度得分\t结果 &lt;br&gt;&quot;); SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&apos;color:red&apos;&gt;&quot;, &quot;&lt;/span&gt;&quot;); Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc= hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; TokenStream tokenStream = analyzer.tokenStream(f.name(), new StringReader(d.get(f.name()))); String fieldContent = highlighter.getBestFragment(tokenStream, d.get(f.name())); System.out.print(&quot;\t&quot; + fieldContent); &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; //存在内存中,新建一个词典 Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index; &#125; /** * 添加文档内容 * @param w * @param name * @throws IOException */ private static void addDoc(IndexWriter w, String name) throws IOException &#123; //创建一个文档 Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc); &#125;&#125; 2.代码解析创建索引123456789101112131415161718private static Directory createIndex(IKAnalyzer analyzer, List&lt;String&gt; products) throws IOException &#123; //存在内存中,新建一个词典 Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); for (String name : products) &#123; addDoc(writer, name); &#125; writer.close(); return index;&#125;private static void addDoc(IndexWriter w, String name) throws IOException &#123; //创建一个文档 Document doc = new Document(); doc.add(new TextField(&quot;name&quot;, name, Field.Store.YES)); w.addDocument(doc);&#125; 上面代码是将List中的内容保存在文档中，使用analyzer分词器分词，创建索引，索引保存在内存中。 IndexWriter 对象用来写索引的。 查询索引1234567891011121314// 3. 查询器String keyword = &quot;西门子 智能&quot;;Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword);// 4. 搜索IndexReader reader = DirectoryReader.open(index);IndexSearcher searcher = new IndexSearcher(reader);int numberPerPage = 1000;System.out.printf(&quot;当前一共有%d条数据%n&quot;, productNames.size());System.out.printf(&quot;查询关键字是：\&quot;%s\&quot;%n&quot;, keyword);ScoreDoc[] hits = searcher.search(query, numberPerPage).scoreDocs;// 5. 显示查询结果showSearchResults(searcher, hits, query, analyzer);// 6. 关闭查询reader.close(); 上面代码是查询代码，首先对构建查询条件Query对象，读取索引，创建IndexSearcher 查询对象，传入查询条件，得到查询结果，将结果解析出来，返回。 分词器创建索引和查询都要用到分词器，在Lucene中分词主要依靠Analyzer类解析实现。Analyzer类是一个抽象类，分词的具体规则是由子类实现的，不同的语言规则，要有不同的分词器， Lucene默认的StandardAnalyzer是不支持中文的分词。 代码中用到了IKAnalyzer分词器，IKAnalyzer是第三方实现的分词器，继承自Lucene的Analyzer类，针对中文文本进行处理的分词器。 打分机制 从案例返回结果来看,有一列匹配度得分,得分越高的排在越前面,排在前面的查询结果也越准确。 打分公式： ​ ​ Lucene库也实现了上面的打分算法，查询结果也会根据分数进行排序。 高亮显示12SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(&quot;&lt;span style=&apos;color:red&apos;&gt;&quot;, &quot;&lt;/span&gt;&quot;);Highlighter highlighter = new Highlighter(simpleHTMLFormatter, new QueryScorer(query)); 将查询结果放到html页面，就会发现查询结果里关键字被标记为红色。在 Lucene库的org.apache.lucene.search.highlight包中提供了关于高亮显示检索关键字的方法，可以对返回的结果中出现了的关键字进行标记。 四、Lucene入门案例二1.案例介绍 1.将14万条商品详细信息到mysql数据库; 2.使用Lucene库创建索引; 3.使用Luncene查询索引,并做分页操作,得到返回查询到的数据,并记录查询时长; 4.使用JDBC连接mysql数据库,采用like查询,对商品进行分页操作,返回查询到的数据,记录查询时长; 5.比较mysql的模糊查询与Lucene全文检索查询。 2.案例二代码引入lucene的jar包,和mysql的驱动包,创建数据库product表,插入数据. 12345678910111213141516171819202122232425262728293031323334/** * 商品bean类 * @author yizl * */public class Product &#123; /** * 商品id */ private int id; /** * 商品名称 */ private String name; /** * 商品类型 */ private String category; /** * 商品价格 */ private float price; /** * 商品产地 */ private String place; /** * 商品条形码 */ private String code; ...... &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165public class TestLucene &#123; private static ProductDao dao = new ProductDao(); public static void main(String[] args) throws Exception &#123; // 1. 准备中文分词器 IKAnalyzer analyzer = new IKAnalyzer(); // 2. 索引 Directory index = createIndex(analyzer); // 3. 查询器 Scanner s = new Scanner(System.in); while (true) &#123; System.out.print(&quot;请输入查询关键字：&quot;); String keyword = s.nextLine(); System.out.println(&quot;当前关键字是：&quot; + keyword); long start = System.currentTimeMillis(); // 查询名字字段 Query query = new QueryParser(&quot;name&quot;, analyzer).parse(keyword); // 4. 搜索 IndexReader reader = DirectoryReader.open(index); IndexSearcher searcher = new IndexSearcher(reader); ScoreDoc[] hits = pageSearch(query, searcher, 1, 10); // 5. 显示查询结果 showSearchResults(searcher, hits, query, analyzer); // 6. 关闭查询 reader.close(); System.out.println(&quot;使用Lucene查询索引,耗时:&quot; + (System.currentTimeMillis() - start) + &quot;毫秒&quot;); System.out.println(&quot;-----------------------分割线-------------------------------&quot;); // 7.通过数据库进行模糊查询 selectProductOfName(keyword); &#125; &#125; /** * 通过mysql商品名查询 */ private static void selectProductOfName(String str) &#123; long start = System.currentTimeMillis(); ResultBean&lt;List&lt;Product&gt;&gt; resultBean = dao.selectProductOfName(str, 1, 10); PageBean pageBean = resultBean.getPageBean(); List&lt;Product&gt; products = resultBean.getData(); System.out.println(&quot;查询出的总条数\t:&quot; + pageBean.getTotal() + &quot;条&quot;); System.out.println(&quot;当前第&quot; + pageBean.getPageNow() + &quot;页,每页显示&quot; + pageBean.getPageSize() + &quot;条数据&quot;); System.out.println(&quot;序号\t结果&quot;); for (int i = 0; i &lt; products.size(); i++) &#123; Product product = products.get(i); System.out.print((i + 1)); System.out.print(&quot;\t&quot; + product.getId()); System.out.print(&quot;\t&quot; + product.getName()); System.out.print(&quot;\t&quot; + product.getPrice()); System.out.print(&quot;\t&quot; + product.getPlace()); System.out.print(&quot;\t&quot; + product.getCode()); System.out.println(&quot;&lt;br&gt;&quot;); &#125; System.out.println(&quot;使用mysql查询,耗时:&quot; + (System.currentTimeMillis() - start) + &quot;毫秒&quot;); &#125; /** * 显示找到的结果 * * @param searcher * @param hits * @param query * @param analyzer * @throws Exception */ private static void showSearchResults(IndexSearcher searcher, ScoreDoc[] hits, Query query, IKAnalyzer analyzer) throws Exception &#123; System.out.println(&quot;序号\t匹配度得分\t结果&quot;); for (int i = 0; i &lt; hits.length; ++i) &#123; ScoreDoc scoreDoc = hits[i]; int docId = scoreDoc.doc; Document d = searcher.doc(docId); List&lt;IndexableField&gt; fields = d.getFields(); System.out.print((i + 1)); System.out.print(&quot;\t&quot; + scoreDoc.score); for (IndexableField f : fields) &#123; System.out.print(&quot;\t&quot; + d.get(f.name())); &#125; System.out.println(&quot;&lt;br&gt;&quot;); &#125; &#125; /** * 分页查询 * * @param query * @param searcher * @param pageNow * 当前第几页 * @param pageSize * 每页显示条数 * @return * @throws IOException */ private static ScoreDoc[] pageSearch(Query query, IndexSearcher searcher, int pageNow, int pageSize) throws IOException &#123; TopDocs topDocs = searcher.search(query, pageNow * pageSize); System.out.println(&quot;查询到的总条数\t&quot; + topDocs.totalHits); System.out.println(&quot;当前第&quot; + pageNow + &quot;页,每页显示&quot; + pageSize + &quot;条数据&quot;); ScoreDoc[] alllScores = topDocs.scoreDocs; List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;(); int start = (pageNow - 1) * pageSize; int end = pageSize * pageNow; for (int i = start; i &lt; end; i++) hitScores.add(alllScores[i]); ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[] &#123;&#125;); return hits; &#125; /** * 创建Index,将数据存入内存中 * * @param analyzer * @return * @throws IOException */ private static Directory createIndex(IKAnalyzer analyzer) throws IOException &#123; long start = System.currentTimeMillis(); Directory index = new RAMDirectory(); IndexWriterConfig config = new IndexWriterConfig(analyzer); IndexWriter writer = new IndexWriter(index, config); List&lt;Product&gt; products = dao.selectAllProduct(); int total = products.size(); int count = 0; int per = 0; int oldPer = 0; for (Product p : products) &#123; addDoc(writer, p); count++; per = count * 100 / total; if (per != oldPer) &#123; oldPer = per; System.out.printf(&quot;索引中，总共要添加 %d 条记录，当前添加进度是： %d%% %n&quot;, total, per); &#125; &#125; System.out.println(&quot;索引创建耗时:&quot; + (System.currentTimeMillis() - start) + &quot;毫秒&quot;); writer.close(); return index; &#125; /** * 往lucene中添加字段 * * @param w * @param p * @throws IOException */ private static void addDoc(IndexWriter w, Product p) throws IOException &#123; Document doc = new Document(); doc.add(new TextField(&quot;id&quot;, String.valueOf(p.getId()), Field.Store.YES)); doc.add(new TextField(&quot;name&quot;, p.getName(), Field.Store.YES)); doc.add(new TextField(&quot;category&quot;, p.getCategory(), Field.Store.YES)); doc.add(new TextField(&quot;price&quot;, String.valueOf(p.getPrice()), Field.Store.YES)); doc.add(new TextField(&quot;place&quot;, p.getPlace(), Field.Store.YES)); doc.add(new TextField(&quot;code&quot;, p.getCode(), Field.Store.YES)); w.addDocument(doc); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221public class ProductDao &#123; private static String url = &quot;jdbc:mysql://localhost:3306/lucene?useUnicode=true&amp;characterEncoding=utf8&quot;; private static String user = &quot;root&quot;; private static String password = &quot;root&quot;; public static Connection getConnection() throws ClassNotFoundException, SQLException &#123; Connection conn = null; // 通过工具类获取连接对象 Class.forName(&quot;com.mysql.jdbc.Driver&quot;); conn = DriverManager.getConnection(url, user, password); return conn; &#125; /** * 批量增加商品 * @param pList */ public void insertProduct(List&lt;Product&gt; pList) &#123; String insertProductTop=&quot;INSERT INTO `product` (`id`, `name`, &quot; + &quot;`category`, `price`, `place`, `code`) VALUES &quot;; Connection conn = null; Statement stmt = null; try &#123; conn = getConnection(); // 3.创建Statement对象 stmt = conn.createStatement(); int count=0; // 4.sql语句 StringBuffer sb = new StringBuffer(); for (int i = 0,len=pList.size(); i &lt; len; i++) &#123; Product product = pList.get(i); sb.append(&quot;(&quot; + product.getId() + &quot;,&apos;&quot; + product.getName() + &quot;&apos;,&apos;&quot; + product.getCategory()+ &quot;&apos;,&quot; + product.getPrice() + &quot;,&apos;&quot; + product.getPlace() + &quot;&apos;,&apos;&quot; + product.getCode() + &quot;&apos;)&quot;); if (i==len-1) &#123; sb.append(&quot;;&quot;); break; &#125;else &#123; sb.append(&quot;,&quot;); &#125; //数据量太大会导致一次执行不了,一次最多执行20000条 if(i%20000==0&amp;&amp;i!=0) &#123; sb.deleteCharAt(sb.length()-1); sb.append(&quot;;&quot;); String sql = insertProductTop+sb; count += stmt.executeUpdate(sql); //将sb清空 sb.delete(0, sb.length()); &#125; &#125; String sql = insertProductTop+sb; // 5.执行sql count += stmt.executeUpdate(sql); System.out.println(&quot;影响了&quot; + count + &quot;行&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; finally &#123; close(conn, stmt); &#125; &#125; /** * 关闭资源 * @param conn * @param stmt */ private void close(Connection conn, Statement stmt) &#123; // 关闭资源 if (stmt != null) &#123; try &#123; stmt.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125; &#125; // public void deleteAllProduct() &#123; Connection conn = null; Statement stmt = null; try &#123; conn = getConnection(); // 3.创建Statement对象 stmt = conn.createStatement(); // 4.sql语句 String sql = &quot;delete from product&quot;; // 5.执行sql int count = stmt.executeUpdate(sql); System.out.println(&quot;影响了&quot; + count + &quot;行&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; finally &#123; // 关闭资源 close(conn, stmt); &#125; &#125; /** * 查询所有商品 */ public List&lt;Product&gt; selectAllProduct() &#123; List&lt;Product&gt; pList=new ArrayList&lt;&gt;(); Connection conn = null; Statement stmt = null; try &#123; conn = getConnection(); // 3.创建Statement对象 stmt = conn.createStatement(); // 4.sql语句 String sql = &quot;select * from product&quot;; // 5.执行sql ResultSet rs = stmt.executeQuery(sql); while (rs.next()) &#123; Product product=new Product(); product.setId(rs.getInt(&quot;id&quot;)); product.setName(rs.getString(&quot;name&quot;)); product.setCategory(rs.getString(&quot;category&quot;)); product.setPlace(rs.getString(&quot;place&quot;)); product.setPrice(rs.getFloat(&quot;price&quot;)); product.setCode(rs.getString(&quot;code&quot;)); pList.add(product); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; finally &#123; // 关闭资源 close(conn, stmt); &#125; return pList; &#125; /** * 通过商品名模糊匹配商品 * @param strName * @param pageNow * @param pageSize * @return */ public ResultBean&lt;List&lt;Product&gt;&gt; selectProductOfName(String strName, int pageNow, int pageSize) &#123; ResultBean&lt;List&lt;Product&gt;&gt; resultBean=new ResultBean&lt;List&lt;Product&gt;&gt;(); PageBean pageBean =new PageBean(); pageBean.setPageNow(pageNow); pageBean.setPageSize(pageSize); List&lt;Product&gt; pList=new ArrayList&lt;&gt;(); Connection conn = null; PreparedStatement pstmt = null; try &#123; conn = getConnection(); // sql语句 String sql = &quot;SELECT id,name,category,place,price,code FROM product&quot; + &quot; where name like ? limit &quot;+(pageNow-1)*pageSize+&quot;,&quot;+pageSize; // 3.创建PreparedStatement对象,sql预编译 pstmt = conn.prepareStatement(sql); // 4.设定参数 pstmt.setString(1, &quot;%&quot; + strName + &quot;%&quot; ); // 5.执行sql,获取查询的结果集 ResultSet rs = pstmt.executeQuery(); while (rs.next()) &#123; Product product=new Product(); product.setId(rs.getInt(&quot;id&quot;)); product.setName(rs.getString(&quot;name&quot;)); product.setCategory(rs.getString(&quot;category&quot;)); product.setPlace(rs.getString(&quot;place&quot;)); product.setPrice(rs.getFloat(&quot;price&quot;)); product.setCode(rs.getString(&quot;code&quot;)); pList.add(product); &#125; String selectCount = &quot;SELECT count(1) c FROM product&quot; + &quot; where name like ? &quot;; pstmt = conn.prepareStatement(selectCount); pstmt.setString(1, &quot;%&quot; + strName + &quot;%&quot; ); ResultSet rs1 = pstmt.executeQuery(); int count=0; while (rs1.next()) &#123; count = rs1.getInt(&quot;c&quot;); &#125; pageBean.setTotal(count); resultBean.setPageBean(pageBean); resultBean.setData(pList); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; finally &#123; // 关闭资源 if (pstmt != null) &#123; try &#123; pstmt.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); throw new RuntimeException(e); &#125; &#125; &#125; return resultBean; &#125;&#125; 12345678910111213141516171819202122232425/** * 返回结果bean * @author yizl * * @param &lt;T&gt; */public class ResultBean&lt;T&gt; &#123; /** * 分页信息 */ private PageBean pageBean; /** * 状态码 */ private Integer code; /** * 提示信息 */ private String msg; /** * 返回数据 */ private T data; 12345678910111213141516171819/** * 分页bean * @author yizl * */public class PageBean &#123; /** * 当前页数 */ private Integer pageNow; /** * 每页条数 */ private Integer pageSize; /** * 总数 */ private Integer total; 4.Lucene的分页查询123456789101112131415private static ScoreDoc[] pageSearch(Query query, IndexSearcher searcher, int pageNow, int pageSize)throws IOException &#123;TopDocs topDocs = searcher.search(query, pageNow * pageSize);System.out.println(&quot;查询到的总条数\t&quot; + topDocs.totalHits);System.out.println(&quot;当前第&quot; + pageNow + &quot;页,每页显示&quot; + pageSize + &quot;条数据&quot;);ScoreDoc[] alllScores = topDocs.scoreDocs;List&lt;ScoreDoc&gt; hitScores = new ArrayList&lt;&gt;();int start = (pageNow - 1) * pageSize;int end = pageSize * pageNow;for (int i = start; i &lt; end; i++)hitScores.add(alllScores[i]);ScoreDoc[] hits = hitScores.toArray(new ScoreDoc[] &#123;&#125;);return hits;&#125; 先把所有的命中数查询出来，在进行分页，有点是查询快，缺点是内存消耗大。 5.结果比较分析1.14万条数据,从创建lucene索引耗时:11678毫秒,创建索引还是比较耗时的,但是索引只用创建一次,后面都查询都可以使用；2.从查询时间来看,使用Lucene查询,基本都在10ms左右,mysql查询耗时在150ms以上,查询速度方面有很大的提升，特别是数据量大的时候更加明显； 3.从查询精准度来说，输入单个的词语可能都能查询到结果，输入组合词语，mysql可以匹配不了，Lucene依然可以查询出来，将匹配度高的结果排在前面，更精准。 6.Lucene索引与mysql数据库对比 Lucene全文检索 mysql数据库 索引 将数据源中的数据–建立反向索引,查询快 对于like查询来说,传统数据库的索引不起作用,还是要全表扫描，查询慢 匹配效果 词元(term)匹配,通过语言分析接口进行关键字拆分，匹配度高 模糊匹配,可能不能匹配相关的词组 匹配度 有匹配度算法,匹配度高的得分高排前面 无匹配程度算法,随机排列 关键字标记 提供高亮显示的Api,可以对查询结果的关键字高亮标记 没有直接使用的api,需要自己封装 五、总结首先我们了解全文检索方法，全文检索搜索非结构化数据速度快等优点，倒排索引是现在最常用的全文检索方法，索引的核心就是怎么创建索引和查询索引。至于怎么实现创建和查询，Apache软件基金会很贴心的为我们Java程序员提供了Lucene开源库，它为我们提供了创建和查询索引的api，这就是我们学习Lucene的目的。]]></content>
      <categories>
        <category>全文检索技术</category>
      </categories>
      <tags>
        <tag>Lucene</tag>
      </tags>
  </entry>
</search>
